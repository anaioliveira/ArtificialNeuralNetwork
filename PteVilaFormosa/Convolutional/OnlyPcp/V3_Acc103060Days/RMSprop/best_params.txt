{'activation_input': 'relu', 'filter': 128, 'kernel': 50, 'hidden_conv_layers': 1, 'hidden_n_layers': 1, 'add_drop': True, 'activation_output': 'linear', 'learning_rate': 0.001, 'batch_size': 50, 'epochs': 250, 'hidden_input_nodes': 100, 'activation_input_den_hid': 'relu', 'drop_value': 0.1, 'activation_input_conv_hid': 'relu'}
NSE: 0.6115164351199458
R2: 0.7373208600552058
PBIAS: -58.01455909232091
RMSE: 29.18428761964186
