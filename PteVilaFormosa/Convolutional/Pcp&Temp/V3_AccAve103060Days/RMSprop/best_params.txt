{'activation_input': 'relu', 'filter': 64, 'kernel': 50, 'hidden_conv_layers': 1, 'hidden_n_layers': 1, 'add_drop': True, 'activation_output': 'linear', 'learning_rate': 0.001, 'batch_size': 40, 'epochs': 350, 'activation_input_conv_hid': 'relu', 'hidden_input_nodes': 10, 'activation_input_den_hid': 'linear', 'drop_value': 0.0}
NSE: 0.6763834754823748
R2: 0.7053960495223727
PBIAS: -23.07597589877988
RMSE: 26.636558744104846
