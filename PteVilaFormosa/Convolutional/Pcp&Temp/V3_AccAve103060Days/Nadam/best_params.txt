{'activation_input': 'relu', 'filter': 64, 'kernel': 5, 'hidden_conv_layers': 1, 'hidden_n_layers': 0, 'add_drop': False, 'activation_output': 'linear', 'learning_rate': 0.001, 'batch_size': 20, 'epochs': 200, 'activation_input_conv_hid': 'relu', 'hidden_input_nodes': 5, 'activation_input_den_hid': 'elu', 'drop_value': 0.2}
NSE: 0.4144417229619236
R2: 0.6818608441657473
PBIAS: 10.928997394003328
RMSE: 35.83008460975279
