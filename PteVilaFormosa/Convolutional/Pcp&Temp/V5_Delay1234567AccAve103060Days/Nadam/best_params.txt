{'activation_input': 'relu', 'filter': 8, 'kernel': 100, 'hidden_conv_layers': 0, 'hidden_n_layers': 0, 'add_drop': False, 'activation_output': 'linear', 'learning_rate': 0.01, 'batch_size': 30, 'epochs': 100, 'activation_input_conv_hid': 'linear', 'hidden_input_nodes': 100, 'activation_input_den_hid': 'softsign', 'drop_value': 0.2}
NSE: 0.7484766197319221
R2: 0.7589397734243424
PBIAS: 5.676603813866857
RMSE: 23.482912078391475
